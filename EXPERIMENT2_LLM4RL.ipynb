{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: LLM+RL Individual Test Episode For Security and Risk Profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we test our hybrid architecture on a single equity, allowing us to observe the learning and troubleshoot the RL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T14:39:13.829574Z",
     "iopub.status.busy": "2024-09-23T14:39:13.829218Z",
     "iopub.status.idle": "2024-09-23T14:39:14.190909Z",
     "shell.execute_reply": "2024-09-23T14:39:14.189908Z",
     "shell.execute_reply.started": "2024-09-23T14:39:13.829533Z"
    },
    "papermill": {
     "duration": 0.761376,
     "end_time": "2024-09-17T19:46:45.797391",
     "exception": false,
     "start_time": "2024-09-17T19:46:45.036015",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext dotenv\n",
    "\n",
    "FUNDAMENTALS_PATH = os.getenv(\"FUNDAMENTALS_PATH\", '/fundamentals')\n",
    "LLM_PROMPTS_PATH = os.getenv(\"LLM_PROMPTS_PATH\", '/prompts')\n",
    "FUNDAMENTALS_PATH = os.getenv(\"FUNDAMENTALS_PATH\", '/fundamentals')\n",
    "HISTORIC_PATH = os.getenv(\"HISTORIC_PATH\", '/historic')\n",
    "MACRO_PATH = os.getenv(\"MACRO_PATH\", '/macro')\n",
    "OPTIONS_PATH = os.getenv(\"OPTIONS_PATH\", '/options')\n",
    "LLM_OUTPUT_PATH = os.getenv(\"LLM_OUTPUT_PATH\", '/llm_data')\n",
    "RL_OUTPUT_PATH = os.getenv(\"RL_OUTPUT_PATH\", '/rl_data')\n",
    "LOGS_PATH = os.getenv(\"LOGS_PATH\", '/logs')\n",
    "paths = [LLM_OUTPUT_PATH, LOGS_PATH, RL_OUTPUT_PATH]\n",
    "\n",
    "for path in paths:\n",
    "    if path and not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "DATA_PATH = './data'\n",
    "module_path = os.path.abspath(os.path.join(os.getcwd(), 'utils'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from openai import OpenAI\n",
    "from rl_agent_utils import *\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "STARTDATE = '2012-01-01'\n",
    "SPLITDATE = '2018-01-01'\n",
    "ENDDATE = '2020-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_OUTPUT_PATH = \"./spottest/\"\n",
    "os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY)\n",
    "RISK = 'r'\n",
    "PROMPT_VERSION = 'v4'\n",
    "TARGET = 'TSLA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate LLM Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = f\"{HISTORIC_PATH}/engineered_{TARGET}_data.parquet\"\n",
    "llm_output_dir = f'{LLM_OUTPUT_PATH}/response/{RISK}/{PROMPT_VERSION}'\n",
    "\n",
    "engineered_df = pd.read_parquet(input_file)\n",
    "engineered_df.set_index('Date', inplace=True)\n",
    "engineered_df = generate_strategy_for_ticker(ticker_df=engineered_df,\n",
    "                                            ticker=TARGET,\n",
    "                                            LLM_OUTPUT_PATH=llm_output_dir,\n",
    "                                            persona=PERSONA,\n",
    "                                            HIGH_RISK_PROFILE=HIGH_RISK_PROFILE if RISK is 'r' else LOW_RISK_PROFILE,\n",
    "                                            HIGH_OBJECTIVES=HIGH_OBJECTIVES if RISK is 'r' else LOW_OBJECTIVES,\n",
    "                                            client=OPENAI_CLIENT,\n",
    "                                            model=OPENAI_MODEL,\n",
    "                                            strategy_yaml_file=f'{LLM_PROMPTS_PATH}/strat_prompt_{PROMPT_VERSION}.yml',\n",
    "                                            news_yaml_file=f'{LLM_PROMPTS_PATH}/analyst_prompt_v1.yml' if PROMPT_VERSION in ['v4'] else None,\n",
    "                                            start_date=STARTDATE,\n",
    "                                            end_date=ENDDATE)\n",
    "\n",
    "engineered_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(engineered_df[[\"strat_signal_long\", \"strat_signal_short\", \"trade_signal\", \"trade_action\", \"action_confidence\"]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_engineered_df = engineered_df[SPLITDATE:ENDDATE].copy()\n",
    "llm_trading_metrics, llm_trades_df = evaluate_trading_metrics(test_engineered_df)\n",
    "\n",
    "pprint(llm_trading_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "money=100_000.\n",
    "stateLength = 30\n",
    "actionSpace = 2\n",
    "bounds = [1, 30]\n",
    "step = 1\n",
    "numberOfEpisodes = 50\n",
    "percentageCosts = [0, 0.1, 0.2]\n",
    "transactionCosts = percentageCosts[1]/100\n",
    "simulator = TradingSimulator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_output_dir = f'{RL_OUTPUT_PATH}/{RISK}/{PROMPT_VERSION}'\n",
    "os.makedirs(rl_output_dir, exist_ok=True)\n",
    "\n",
    "train_file = f'{rl_output_dir}/{TARGET}_train_results.pkl'\n",
    "test_file = f'{rl_output_dir}/{TARGET}_test_results.pkl'\n",
    "train_env_file = f'{rl_output_dir}/{TARGET}_train_env.pkl'\n",
    "test_env_file = f'{rl_output_dir}/{TARGET}_test_env.pkl'\n",
    "q_train_file = f'{rl_output_dir}/{TARGET}_train_q_values.pkl'\n",
    "q_test_file = f'{rl_output_dir}/{TARGET}_test_q_values.pkl'\n",
    "\n",
    "if all(os.path.exists(p) for p in [train_file, test_file, train_env_file, test_env_file, q_train_file, q_test_file]):\n",
    "    with open(train_file, 'rb') as f:\n",
    "        train_results = pickle.load(f)\n",
    "    with open(test_file, 'rb') as f:\n",
    "        test_results = pickle.load(f)\n",
    "    with open(train_env_file, 'rb') as f:\n",
    "        train_env = pickle.load(f)\n",
    "    with open(test_env_file, 'rb') as f:\n",
    "        test_env = pickle.load(f)\n",
    "    with open(q_train_file, 'rb') as f:\n",
    "        qt0, qt1 = pickle.load(f)\n",
    "    with open(q_test_file, 'rb') as f:\n",
    "        q0, q1 = pickle.load(f)\n",
    "else:\n",
    "    strat, train_env, qt0, qt1, test_env, q0, q1 = simulator.simulateNewStrategy(\n",
    "        stock_df=engineered_df.copy(),\n",
    "        startingDate=STARTDATE,\n",
    "        endingDate=ENDDATE,\n",
    "        splitingDate=SPLITDATE,\n",
    "        verbose=True,\n",
    "        plotTraining=True,\n",
    "        rendering=True,\n",
    "        showPerformance=True,\n",
    "        saveStrategy=True,\n",
    "        money=money,\n",
    "        actionSpace=actionSpace,\n",
    "        stateLength=stateLength,\n",
    "        bounds=bounds,\n",
    "        step=step,\n",
    "        numberOfEpisodes=numberOfEpisodes,\n",
    "        transactionCosts=transactionCosts,\n",
    "        ticker_symbol=TARGET\n",
    "    )\n",
    "    analyser = PerformanceEstimator(train_env.data)\n",
    "    train_results = analyser.getComputedPerformance()\n",
    "    analyser = PerformanceEstimator(test_env.data)\n",
    "    test_results = analyser.getComputedPerformance()\n",
    "    with open(train_file, 'wb') as f:\n",
    "        pickle.dump(train_results, f)\n",
    "    with open(test_file, 'wb') as f:\n",
    "        pickle.dump(test_results, f)\n",
    "    with open(train_env_file, 'wb') as f:\n",
    "        pickle.dump(train_env, f)\n",
    "    with open(test_env_file, 'wb') as f:\n",
    "        pickle.dump(test_env, f)\n",
    "    with open(q_train_file, 'wb') as f:\n",
    "        pickle.dump((qt0, qt1), f)\n",
    "    with open(q_test_file, 'wb') as f:\n",
    "        pickle.dump((q0, q1), f)\n",
    "\n",
    "pprint(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_engineered_df = engineered_df[STARTDATE:SPLITDATE].copy()\n",
    "train_engineered_df['LLM_Trade_Action'] = train_engineered_df['trade_action']\n",
    "train_engineered_df['trade_action'] = train_env.data['action'].apply(lambda x: 1 if x == 1 else 0)\n",
    "train_engineered_df['reward'] = train_env.data['reward']\n",
    "train_engineered_df['other_reward'] = train_env.data['other_reward']\n",
    "# train_engineered_df['unshaped_reward'] = train_env.data['unshaped_reward']\n",
    "llm_trading_metrics, llm_trades_df = evaluate_trading_metrics(train_engineered_df, rl_env=train_env)\n",
    "llm_trades_df['cumulative_returns'] = (1 + train_env.data['returns']).cumprod() - 1\n",
    "\n",
    "pprint(llm_trading_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_trades_df[['cumulative_returns', 'returns','reward']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_llm_trade(llm_trades_df, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_engineered_df = engineered_df[SPLITDATE:ENDDATE].copy()\n",
    "test_engineered_df['LLM_Trade_Action'] = test_engineered_df['trade_action']\n",
    "test_engineered_df['trade_action'] = test_env.data['action'].apply(lambda x: 1 if x == 1 else 0)\n",
    "test_engineered_df['reward'] = test_env.data['reward']\n",
    "test_engineered_df['other_reward'] = test_env.data['other_reward']\n",
    "\n",
    "# test_engineered_df['unshaped_reward'] = test_env.data['unshaped_reward']\n",
    "llm_trading_metrics, llm_trades_df = evaluate_trading_metrics(test_engineered_df, rl_env=test_env)\n",
    "llm_trades_df['cumulative_returns'] = (1 + test_env.data['returns']).cumprod() - 1\n",
    "\n",
    "pprint(llm_trading_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(llm_trades_df[['entropy', 'action_confidence', \"strat_signal_long\", \"strat_signal_short\"]].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(llm_trades_df[['cumulative_returns', 'returns','reward','other_reward']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_llm_trade(llm_trades_df, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env.data['2018-10-01':'2019-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test_env.data[['action', 'trade_action', 'trade_signal', 'returns']]\n",
    "d = t[t['action'] != t['trade_action']]\n",
    "d"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5722911,
     "sourceId": 9421991,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 197612253,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "quant_drl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1234.187031,
   "end_time": "2024-09-17T20:07:16.406924",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-17T19:46:42.219893",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
